# ğŸ„ Mushroom Classification using Machine Learning

> An AI-powered Machine Learning system for automatic mushroom classification into **edible** or **poisonous** categories using multiple supervised learning algorithms.
>
> This project demonstrates a complete ML pipeline including preprocessing, encoding strategies, model comparison, feature importance analysis, hyperparameter tuning, and overfitting detection â€” delivering a highly interpretable and robust classification system.

<br>

![Python](https://img.shields.io/badge/Python-3.x-3776AB?style=flat-square&logo=python&logoColor=white)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-ML-F7931E?style=flat-square&logo=scikit-learn&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-Data-150458?style=flat-square&logo=pandas&logoColor=white)
![Accuracy](https://img.shields.io/badge/Accuracy-100%25-2ea44f?style=flat-square)
![Models](https://img.shields.io/badge/Models-6-blueviolet?style=flat-square)
![License](https://img.shields.io/badge/License-MIT-lightgrey?style=flat-square)

---


## ğŸ“– Overview

The system classifies mushrooms into:

| Label | Class | Description |
|-------|-------|-------------|
| `e` | **Edible** | Safe for consumption |
| `p` | **Poisonous** | Toxic â€” must be correctly identified |

The dataset consists entirely of **categorical features**, making this project an excellent case study in:

- Categorical data encoding
- Tree-based vs. distance-based models
- Feature importance & interpretability
- Model validation & generalization

> âœ… This project highlights how machine learning can assist in **toxicology risk assessment** and **decision support systems**.

---

## ğŸ¯ Objectives

### ğŸ”¹ 1. Data Exploration & Preprocessing

- Analyze dataset structure and class balance
- Check missing values & duplicates
- Detect rare categories (< 1%)
- Perform optional PCA-based outlier inspection
- Apply encoding strategies

### ğŸ”¹ 2. Encoding Strategies

Two encoding techniques were implemented and compared *(see [Encoding Strategies](#-encoding-strategies) below)*.

### ğŸ”¹ 3. Model Development

Six supervised learning models were implemented and evaluated across five metrics: **Accuracy Â· Precision Â· Recall Â· F1-Score Â· Confusion Matrix**

### ğŸ”¹ 4. Hyperparameter Tuning

Applied `GridSearchCV` to optimize Random Forest with 3-fold cross-validation.

### ğŸ”¹ 5. Model Validation & Overfitting Detection

Multi-layered validation to ensure generalization â€” 5-fold CV, learning curves, and permutation importance.

---

## ğŸ·ï¸ Encoding Strategies

### Label Encoding â€” Tree-Friendly

Efficient for tree-based models. Used with:

- Decision Tree
- Random Forest
- Categorical Naive Bayes

### One-Hot Encoding â€” Distance-Friendly

Suitable for distance and margin-based models. Scaled using `StandardScaler(with_mean=False)`. Used with:

- K-Nearest Neighbors
- Support Vector Machine
- Gaussian Naive Bayes

---

## ğŸ¤– Models Implemented

| Model | Encoding | Kernel / Config |
|-------|----------|-----------------|
| Decision Tree | Label | â€” |
| **Random Forest** | Label | **GridSearchCV tuned** |
| K-Nearest Neighbors (KNN) | One-Hot + Scaled | Euclidean, k=5 |
| Support Vector Machine | One-Hot + Scaled | RBF Kernel |
| Categorical Naive Bayes | Label | Categorical likelihood |
| Gaussian Naive Bayes | One-Hot + Scaled | Gaussian likelihood |

**Evaluation metrics applied to every model:**

| Metric | Description |
|--------|-------------|
| Accuracy | Overall correct predictions |
| Precision | True positives / predicted positives |
| Recall | True positives / actual positives |
| F1-Score | Harmonic mean of precision & recall |
| Confusion Matrix | Per-class prediction breakdown |

---

## âš™ï¸ Hyperparameter Tuning

`GridSearchCV` applied to Random Forest:

```python
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
}
# cv=3, scoring='accuracy'
```

**Best Parameters Found:**

```python
{'max_depth': None, 'n_estimators': 100}
```

---

## âœ… Model Validation & Overfitting Detection

| Technique | Purpose |
|-----------|---------|
| **5-Fold Cross-Validation** | Confirms stable performance across all data splits |
| **Train vs. Test Accuracy** | Detects gap between training and generalization |
| **Learning Curve Analysis** | Visualizes bias-variance tradeoff over dataset size |
| **Permutation Importance** | Model-agnostic feature relevance validation |

> âœ” Results show **strong generalization with no significant overfitting.**

---

## ğŸ† Best Performing Model

### ğŸŒ² Random Forest Classifier

After hyperparameter tuning â€” `{'max_depth': None, 'n_estimators': 100}`

| Metric | Score |
|--------|-------|
| **Accuracy** | âœ… 100% |
| **Precision** | âœ… 1.00 |
| **Recall** | âœ… 1.00 |
| **F1-Score** | âœ… 1.00 |
| **CV Stability** | âœ… Stable across all folds |

---

## ğŸ”¬ Feature Importance & Ablation Study

Feature importance was analyzed using two methods:

- **Random Forest built-in importance** (Mean Decrease in Impurity)
- **Permutation Importance** â€” model-agnostic, shuffle-based

### ğŸš¨ Key Insight: `odor` is the Single Most Important Feature

> *"Mushroom smell is the dominant predictive factor for toxicity."*

### Ablation Study â€” Effect of Removing `odor`

| Condition | Accuracy | Î” Change |
|-----------|----------|----------|
| âœ… **With** `odor` | **100%** | â€” |
| âš ï¸ **Without** `odor` | **88.6%** | â†“ âˆ’11.4 pp |

Even without `odor`, the model significantly outperforms random guessing (50%) â€” confirming that other structural features (gill color, spore print, ring type) still carry **meaningful predictive signal**.

---


## ğŸ§  ML Concepts Demonstrated

- Categorical Encoding â€” Label vs. One-Hot
- Tree-based vs. Distance-based model comparison
- Hyperparameter tuning with `GridSearchCV`
- Cross-validation (3-fold tuning, 5-fold evaluation)
- Learning curve analysis
- Feature importance (MDI) & Permutation Importance
- Feature ablation analysis
- Overfitting detection & mitigation

---

## ğŸš€ Project Highlights

- âœ… Complete end-to-end ML pipeline
- âœ… Multiple model comparison across two encoding strategies
- âœ… Perfect classification performance (100% accuracy)
- âœ… Strong interpretability via feature importance & ablation
- âœ… Robust multi-layered validation strategy

---


## ğŸ‘©â€ğŸ’» Author

<div align="center">

### âœ¨ *Eng. Paula Hanna Naguib* âœ¨

</div>

---

<div align="center">
  <sub>ğŸ“Œ <em>"Machine Learning transforms raw categorical data into life-saving insights."</em></sub>
</div>
